% vim: set textwidth=72 :
% Copyright (C) 2013 Roy E Lowrance
% See the file COPYING.txt for copying conditions.

\documentclass{article}
\usepackage{amssymb,latexsym,amsmath}
\usepackage{verbatim}
\let\code\texttt % in line source code

\begin{document}
\title{Testing Your Map-reduce Job Outside of Hadoop}
\author{Roy E Lowrance}
\maketitle

%\abstract{XXX}

\section{Problem}

You want to test your map-reduce job before you submit it to Hadoop, perhaps because the 
debugging tools in the Hadoop streaming interface are lacking.

\section{Solution}

The solution has three parts:
\begin{itemize}
  \item Write the mapper so that it can process less than all the input.
  \item In the mapper, write debugging information into the key-value
    file by using  keys designated for that purpose. Modify the reducer to
    handle these keys appropriately.
  \item Write a shell script to run map-reduce locally, without
    Hadoop.
\end{itemize}

\subsection{Map a subset of the input}

Write your map program so that it can run from the command line and as a
Hadoop command. When it runs from the command line, you may need to
limit the amount of input it reads, if it reads a lot of input or
creates a lot of key-value pairs for your reduce job.

To do this, write one map program that has an optional parameter. If the
optional parameter is present, its value is used to limit the scope of
the map program. One way to do this is to have let the optional
parameter be READLIMIT, an integer with a default value of -1. If
READLIMIT is non-negative, the map program stops after reading the
indicated number of input records. If READLIMIT is negative, the map
program reads and processes all the input records. (The READLIMIT idea
is common in R for controlling how many records are read and processed
from a file.)

\subsection{Put debugging information into the key-value pairs}

The reducer will read all the key-value pairs after they have been
combined and sorted by key. Designate one set of keys as only containing
debugging information and have the reducer handle records with these
keys specially. The keys and values are strings. One choice is to say
that any key beginning with a ``\#'' is for debugging work, not regular
processing.

\subsection{Shell script}

Running the job is work that is best delegated to a script. We propose
that the script take the same initial parameters as the script
\code{map-reduce-hadoop.sh} described in the recipe ``Run Many Hadoop
Jobs''. Thus the parameters of the script will be
\begin{itemize}
  \item INPUT--name of the input file. This is also the first parameter
    in \code{map-reduce-hadoop.sh}.
  \item JOB--name of the job. The name of the job, the same paraemeter
    as for \code{map-reduce-hadoop.sh}. The mapper is \code{JOB-map.lua}
    and the reducer is \code{JOB-reduce.lua}.
  \item READLIMIT--integer. Not a parameter to
    \code{map-reduce-hadoop.sh}. 
\end{itemize}


\section{Discussion}

The sample code is a modification of the code used for the recipe
``Using Torch on Hadoop.''

The mapper program is modified to accept the optional READLIMIT
argument and to write diagnostic information to its output stream using
keys that begin with ``\#''.

\verbatiminput{test-hadoop-job-assets/countInput-map.lua}

The reducer program looks for the diagnostic records and writes them to
stderr. The output is written to stdout. In some uses, you may want to
write the diagnostic output to stdout as well.

\verbatiminput{test-hadoop-job-assets/countInput-reduce.lua}

The shell script \code{map-reduce-local.sh} is just below. The only
trick is that you need to define the output directory before running the
script.

\verbatiminput{test-hadoop-job-assets/map-reduce-local.sh}

The script \code{go-map.sh} runs just
the mapper. It executes the mapper program as a command.

\verbatiminput{test-hadoop-job-assets/go-map.sh}

The shell script \code{go-map-reduce.sh} knowns the names of the input
file and job and the READLIMIT.

\verbatiminput{test-hadoop-job-assets/go-map-reduce.sh}


Below is the input file \code{courant-abel-prize-winners.txt}.

\verbatiminput{test-hadoop-job-assets/courant-abel-prize-winners.txt}

\section{See also}

This recipe is free documentation. You can modify it by visiting
github for account ``rlowrance'' and forking the repo
``torch-cookbook.''

\end{document}


